{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Laboratorio_2_Redes_Convolucionales_Diplomado_IA_vAlumnos(2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d11c6754705464883e121739c116c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e020b32c4aa64b0a9fed46039856673d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_44ae40351ec54752829429a810b70d8e",
              "IPY_MODEL_cb4dc9dbcc19471c9030d3f865df14c0",
              "IPY_MODEL_435de05354704c7284cfc9e57d0f77c8"
            ]
          }
        },
        "e020b32c4aa64b0a9fed46039856673d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44ae40351ec54752829429a810b70d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fdcdfae618c847a9b5131ff5b9785521",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86ded705b75c47adb3df02543a952039"
          }
        },
        "cb4dc9dbcc19471c9030d3f865df14c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_58e6683178784cd8aa305eb3ee3e6c43",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c634599d73d24c50b0de07f1d982118f"
          }
        },
        "435de05354704c7284cfc9e57d0f77c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c17904437ac44dd5af226a183aa23e60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 34090086.98it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_485f22c3d7124962843562151cc55a59"
          }
        },
        "fdcdfae618c847a9b5131ff5b9785521": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86ded705b75c47adb3df02543a952039": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58e6683178784cd8aa305eb3ee3e6c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c634599d73d24c50b0de07f1d982118f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c17904437ac44dd5af226a183aa23e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "485f22c3d7124962843562151cc55a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff1a6140729e415b9f44504f222a25d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_644d02913824465d8bd04c6d12440e90",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ffc4902ed3fa487087bd5b004bfb937f",
              "IPY_MODEL_66d5d296d201468e8b48682d47eb3494",
              "IPY_MODEL_88be0abfeaa84cf3aae0d028fe625bd3"
            ]
          }
        },
        "644d02913824465d8bd04c6d12440e90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffc4902ed3fa487087bd5b004bfb937f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c3a8d3aad164d0d8488fdcd82968d8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17bab42fe7644caf8c6f6af23280d166"
          }
        },
        "66d5d296d201468e8b48682d47eb3494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed5ca0e07e6d452aa616f3b194af3fa6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0435c0d22dc740969f1b6ef7e43bd87b"
          }
        },
        "88be0abfeaa84cf3aae0d028fe625bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76cd2b0e08a44349af6c510bb8422496",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 613107.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f7aaa5862db94ec38968cdbc58ab6fb6"
          }
        },
        "4c3a8d3aad164d0d8488fdcd82968d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17bab42fe7644caf8c6f6af23280d166": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed5ca0e07e6d452aa616f3b194af3fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0435c0d22dc740969f1b6ef7e43bd87b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76cd2b0e08a44349af6c510bb8422496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f7aaa5862db94ec38968cdbc58ab6fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0534fd9193cc4ba08ee89d51ed845999": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78d6ab99740e454a873effcfdef1f877",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a2eded5486aa4ef394db4d81cbef9353",
              "IPY_MODEL_fea4c5f2599946f9a038422b11636bc6",
              "IPY_MODEL_647dfac1a1db4a738a97c12d5002488e"
            ]
          }
        },
        "78d6ab99740e454a873effcfdef1f877": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2eded5486aa4ef394db4d81cbef9353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bb5d66ff46ae40068fa51a529d989f21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5518d978182b4cb684566fe8ca66dbee"
          }
        },
        "fea4c5f2599946f9a038422b11636bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_928631215cb64e3aa0de98ddf3d6b9b5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_420678c9ad54422b8885f6c34dfce58e"
          }
        },
        "647dfac1a1db4a738a97c12d5002488e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f5e12767ae684a0d88858112f5617552",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:00&lt;00:00, 9850161.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_92653d40975347f4a768e54fb38c4da1"
          }
        },
        "bb5d66ff46ae40068fa51a529d989f21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5518d978182b4cb684566fe8ca66dbee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "928631215cb64e3aa0de98ddf3d6b9b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "420678c9ad54422b8885f6c34dfce58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5e12767ae684a0d88858112f5617552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "92653d40975347f4a768e54fb38c4da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0c2750b7746746948430392a36df6f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ee839e95d3c74c899d55b059c381c19c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aba1be7b1abf477889ae418ab67f9447",
              "IPY_MODEL_33e9e5cb4b2d4747ab2b1d0897312fdb",
              "IPY_MODEL_5ec396d11e184bb0aef5961e6134d64a"
            ]
          }
        },
        "ee839e95d3c74c899d55b059c381c19c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aba1be7b1abf477889ae418ab67f9447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3438dee479034318b1e2795cb83f0070",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_881529d3ef374ba9a23294621a8e1c6a"
          }
        },
        "33e9e5cb4b2d4747ab2b1d0897312fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db3dde4a5d654efea44641131455f6a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a29a59bb80fa44b691def915fe13294a"
          }
        },
        "5ec396d11e184bb0aef5961e6134d64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06f183c27fbc4865baf647bf772ca6b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 147513.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8eaca307a6fd45e1afb66236634b8808"
          }
        },
        "3438dee479034318b1e2795cb83f0070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "881529d3ef374ba9a23294621a8e1c6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db3dde4a5d654efea44641131455f6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a29a59bb80fa44b691def915fe13294a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06f183c27fbc4865baf647bf772ca6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8eaca307a6fd45e1afb66236634b8808": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7de1def65a14761912025c2dcc3f75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18ee03ac1f554233b536eaba2969881f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5286ac7c9fed409685788583b6e4a74d",
              "IPY_MODEL_a5b1d5a1317e4ec082217a5e094554b8",
              "IPY_MODEL_0b77007edf3c485b8d27f7bc13489a56"
            ]
          }
        },
        "18ee03ac1f554233b536eaba2969881f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5286ac7c9fed409685788583b6e4a74d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31c7090efbd0440eb95d918766c3e5d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07bc5dedb8ee47798033b868ad57a1fb"
          }
        },
        "a5b1d5a1317e4ec082217a5e094554b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_836807a99f7c4d838837fc3db3937f12",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33843c53b36e4bec9d09c6c5cdaae011"
          }
        },
        "0b77007edf3c485b8d27f7bc13489a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ce4a9b1a4a1435b8c220f6e1cfcccfd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:03&lt;00:00, 59314828.55it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21388bbf1fe645ccba304af08104058f"
          }
        },
        "31c7090efbd0440eb95d918766c3e5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07bc5dedb8ee47798033b868ad57a1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "836807a99f7c4d838837fc3db3937f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33843c53b36e4bec9d09c6c5cdaae011": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ce4a9b1a4a1435b8c220f6e1cfcccfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21388bbf1fe645ccba304af08104058f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "cf49e42d8ae526647a552259a46dfa8f53ce985d9771a2498166807dc176ee60"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Laboratorio 2 - Redes Convolucionales - Diplomado Inteligencia Artificial UC\n",
        "\n",
        "**IMPORTANTE: habrá un bonus de 1 décima para todos aquellos alumnos/as que muestren buen orden en sus respuestas (esto aplica a legibilidad de código, buena redacción, formalidad, organización del jupyter notebook, seguimiento de instrucciones, etc). El criterio lo pondrá cada ayudante corrector. La nota máxima obtenible en el laboratorio es 7.0.**\n",
        "\n",
        "En este laboratorio nos interiorizaremos en cómo funciona Pytorch (https://pytorch.org/), el framework de Facebook para implementar Redes Neuronales Profundas.\n",
        "\n",
        "Vamos a ver varias partes distintas del flujo de entrenamiento, desde cómo cargamos los datos, cómo creamos redes, cómo las entrenamos y cómo validamos su rendimiento.\n",
        "\n",
        "Fecha de entrega: viernes 24 de septiembre a las 23:59."
      ],
      "metadata": {
        "id": "CzO98wJgjmOd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## El Tensor: la unidad fundamental.\n",
        "\n",
        "Los tensores son el elemento fundamental con que trabajarán nuestras redes profundas. Un tensor es simplemente una matriz de n-dimensiones. \n",
        "\n",
        "* En **imágenes**, usamos tensores de 4 dimensiones: 3 dimensiones (alto, ancho y color) más una cuarta dimensión asociada a los elementos del batch.\n",
        "\n",
        "* Cuando trabajamos con **texto** podemos tener tensores en 3 dimensiones (dimensión de embedding, palabras y batch).\n",
        "\n",
        "* Si trabajamos con **videos** tenemos que agregar otra dimensión para el tiempo. En fin, todos estos datos distintos al final se representan como matrices de números en 3, 4 ó 5 dimensiones distintas.\n",
        "\n",
        "Pytorch representa los tensores via la clase torch.Tensor. Todas las redes neuronales que hagamos requieren tensores para poder trabajar. Nuestros datasets no servirán de nada si no podemos transformarlos en tensores que podamos ocupar con nuestras redes. Si han trabajado con *ndarray* de Numpy la forma de ocuparlos es muy similar. Veamos un tensor de ejemplo de 3 dimensiones: ancho, alto y batch. "
      ],
      "metadata": {
        "id": "Og-s3Wv2oEOe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import torch\r\n",
        "\r\n",
        "batch_dim = 5\r\n",
        "alto = 2\r\n",
        "ancho = 3\r\n",
        "tensor_ejemplo = torch.randn((batch_dim, ancho, alto)).float() # Tensor aleatorio\r\n",
        "print(\"El tensor es: {}\\n\".format(tensor_ejemplo))\r\n",
        "print(\"La forma del tensor es: {}\".format(tensor_ejemplo.shape))\r\n",
        "print(\"El tipo del tensor es: {}\".format(type(tensor_ejemplo)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El tensor es: tensor([[[ 0.5023,  0.8123],\n",
            "         [ 0.5473,  0.3693],\n",
            "         [ 1.0631,  0.1299]],\n",
            "\n",
            "        [[ 1.0653,  0.2828],\n",
            "         [-1.2360,  1.7173],\n",
            "         [-0.0498, -0.4874]],\n",
            "\n",
            "        [[-0.1445,  0.5369],\n",
            "         [ 0.4973, -0.1310],\n",
            "         [-0.0073, -0.7955]],\n",
            "\n",
            "        [[-0.9432, -0.2090],\n",
            "         [-1.6882, -0.2673],\n",
            "         [ 1.3112,  1.3560]],\n",
            "\n",
            "        [[ 1.1331,  1.6532],\n",
            "         [-0.3485, -0.2880],\n",
            "         [ 2.4041,  0.5108]]])\n",
            "\n",
            "La forma del tensor es: torch.Size([5, 3, 2])\n",
            "El tipo del tensor es: <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "metadata": {
        "id": "Eh5omMrW5bUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116b2238-1c22-4003-bda7-cc0fc01b06e3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear un tensor desde un arreglo de Python es sencillo:"
      ],
      "metadata": {
        "id": "UHpZ99Rvjgte"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "arreglo = [[1, 2, 3], [4, 5, 6]]\r\n",
        "tensor_desde_arreglo = torch.tensor(arreglo)\r\n",
        "print(tensor_desde_arreglo, tensor_desde_arreglo.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]]) torch.Size([2, 3])\n"
          ]
        }
      ],
      "metadata": {
        "id": "Mn84KtqwjObX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd6b519c-0721-417b-9559-10794ddbe61f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uno trabaja los tensores de la misma manera que cualquier otra variable numérica en Python. Se pueden, sumar y restar sin problema. La multiplicación por escalares no supone problema y la multiplicación de tensores también está soportada.\n",
        "\n"
      ],
      "metadata": {
        "id": "jwE7bG-56rx6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "tensor_1 = torch.randn((10,2,3))\r\n",
        "tensor_2 = torch.randn((10,2,3))\r\n",
        "\r\n",
        "tensor_3 = tensor_1 + tensor_2\r\n",
        "\r\n",
        "print(tensor_1)\r\n",
        "print(tensor_2)\r\n",
        "print(tensor_3)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 1.1561, -0.2390, -0.4723],\n",
            "         [ 0.3784,  0.8794, -0.0272]],\n",
            "\n",
            "        [[ 1.6080,  3.3015,  1.1861],\n",
            "         [ 2.7892,  1.7349,  1.2691]],\n",
            "\n",
            "        [[ 0.5322, -1.1254, -0.6672],\n",
            "         [-0.3613, -1.1473,  0.3957]],\n",
            "\n",
            "        [[ 1.4840,  0.5810,  0.6968],\n",
            "         [ 0.2768, -0.4107, -0.6268]],\n",
            "\n",
            "        [[-0.3333, -0.4698, -0.4135],\n",
            "         [-0.4402, -0.6454,  0.9401]],\n",
            "\n",
            "        [[-0.5287,  0.5258,  0.5647],\n",
            "         [ 0.8839,  1.4378, -0.0232]],\n",
            "\n",
            "        [[ 1.4831, -0.6276, -2.5350],\n",
            "         [ 0.3866,  0.1163,  0.1359]],\n",
            "\n",
            "        [[-0.7920, -2.3046,  0.7347],\n",
            "         [ 0.0932, -0.1707, -0.3865]],\n",
            "\n",
            "        [[-0.6419,  0.1291,  0.1302],\n",
            "         [-0.0546,  0.2171,  0.8134]],\n",
            "\n",
            "        [[ 0.4091,  0.4903, -1.8645],\n",
            "         [-0.8550,  0.2210, -0.9958]]])\n",
            "tensor([[[ 0.0955, -1.3534,  0.3427],\n",
            "         [-0.6779,  0.8506,  0.1052]],\n",
            "\n",
            "        [[-1.1613,  0.6241,  1.2618],\n",
            "         [ 0.1451,  0.5837,  0.9864]],\n",
            "\n",
            "        [[-0.3850,  0.5997,  1.9053],\n",
            "         [ 0.8950, -0.0987,  0.3296]],\n",
            "\n",
            "        [[ 2.7670,  0.5995, -0.0072],\n",
            "         [-0.7128,  0.8942, -1.2545]],\n",
            "\n",
            "        [[ 0.2140,  0.1689,  2.2134],\n",
            "         [ 0.4464, -1.1056,  1.1149]],\n",
            "\n",
            "        [[-0.2742, -0.7573, -1.8601],\n",
            "         [ 0.3442,  1.1742,  0.5430]],\n",
            "\n",
            "        [[ 1.2840, -0.6063, -0.2284],\n",
            "         [-0.5032, -1.8025, -1.2462]],\n",
            "\n",
            "        [[-0.3753, -1.0737, -0.7483],\n",
            "         [ 0.9591, -1.6162,  0.5069]],\n",
            "\n",
            "        [[-0.0518,  0.5721, -1.0933],\n",
            "         [ 0.5883,  1.1593,  0.7542]],\n",
            "\n",
            "        [[ 0.0608, -1.0174,  0.8608],\n",
            "         [ 0.7825, -1.0119,  0.8147]]])\n",
            "tensor([[[ 1.2516, -1.5924, -0.1296],\n",
            "         [-0.2996,  1.7301,  0.0780]],\n",
            "\n",
            "        [[ 0.4467,  3.9256,  2.4479],\n",
            "         [ 2.9342,  2.3186,  2.2554]],\n",
            "\n",
            "        [[ 0.1472, -0.5257,  1.2381],\n",
            "         [ 0.5337, -1.2459,  0.7253]],\n",
            "\n",
            "        [[ 4.2510,  1.1805,  0.6896],\n",
            "         [-0.4360,  0.4835, -1.8814]],\n",
            "\n",
            "        [[-0.1193, -0.3009,  1.8000],\n",
            "         [ 0.0063, -1.7509,  2.0550]],\n",
            "\n",
            "        [[-0.8029, -0.2315, -1.2953],\n",
            "         [ 1.2281,  2.6119,  0.5197]],\n",
            "\n",
            "        [[ 2.7671, -1.2339, -2.7634],\n",
            "         [-0.1166, -1.6862, -1.1103]],\n",
            "\n",
            "        [[-1.1673, -3.3783, -0.0136],\n",
            "         [ 1.0523, -1.7869,  0.1204]],\n",
            "\n",
            "        [[-0.6937,  0.7012, -0.9631],\n",
            "         [ 0.5338,  1.3765,  1.5676]],\n",
            "\n",
            "        [[ 0.4699, -0.5271, -1.0037],\n",
            "         [-0.0725, -0.7909, -0.1811]]])\n"
          ]
        }
      ],
      "metadata": {
        "id": "OH-U3PPi7az0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74f2bb6-0cf9-4472-93fd-a15e92a3c8fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos indexarlos:"
      ],
      "metadata": {
        "id": "PoNoKKFATdEv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "tensor_indexado = tensor_1[0:2,0,0]\r\n",
        "print(tensor_indexado, tensor_indexado.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.1561, 1.6080]) torch.Size([2])\n"
          ]
        }
      ],
      "metadata": {
        "id": "2OUPry8-TcGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2c4f41-0438-4c29-924d-446adbe568b4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sobre la dimensión batch\n",
        "\n",
        "La dimensión de batch es importante pues es la que nos permite poder entrenar de forma paralela en nuestras GPUs. El estándar de Pytorch es que ésta es la primera dimensión de nuestros tensores siempre. Aunque solo evaluar un elemento en nuestra red, este debe tener una dimensión de batch en su primer lugar o sino no funcionará. También es necesario mencionar que Pytorch espera siempre que la dimensión del canal vaya antes que las dimensiones de ancho y alto en imágenes."
      ],
      "metadata": {
        "id": "KGAdf1Zz7a8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sobre el dispositivo asociado\n",
        "\n",
        "Los tensores son procesados por la CPU o por una GPU. Como quizás hemos escuchado antes, sabemos que parte de la explosión de Deep Learning viene por la disponibilidad de GPUs cada vez más poderosas. Para poder trabajar en GPU un tensor tenemos que hacer lo siguiente:"
      ],
      "metadata": {
        "id": "eX3ER77PS_H_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "tensor_nuevo = torch.randn((1,2,3))     # Por defecto el tensor está en CPU\r\n",
        "tensor_nuevo_gpu = tensor_nuevo.cuda()  # Creé una copia de tensor_nuevo en GPU!\r\n",
        "otra_forma = tensor_nuevo.to('cuda')    # Creé otra copia de tensor_nuevo en GPU!"
      ],
      "outputs": [],
      "metadata": {
        "id": "5Ln8Wq3wURfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición del Modelo\n",
        "Como vimos en el laboratorio pasado, definir un modelo de aprendizaje profundo consiste en definir una nueva clase que herede de torch.nn.Module.\n",
        "\n",
        "Esta clase debe implementar dos métodos para funcionar como un modelo válido en Pytorch:\n",
        "\n",
        "* Método \\_\\_init\\_\\_(self): el constructor de la clase. Aquí es donde usualmente definiremos todos los elementos arquitéctonicos de nuestra red. Aquí definiremos que capas tendrá, qué funciones de activación, funciones de pooling, etc.\n",
        "\n",
        "* Método forward(self, input): define las conexiones entre capas del modelo, o cómo debe fluir la información que entra en él. Debe retornar un tensor.\n",
        "\n",
        "### Elementos arquitectónicos\n",
        "\n",
        "Todos estos elementos están definidos en el paquete torch.nn (de Neural Networks). Todos derivan de la clase torch.nn.Module.\n",
        "\n",
        "* **Linear:** capa lineal. Toma como parámetros las cantidades de neuronas de entrada y de salida.\n",
        "* **Conv1d, Conv2d, Conv3d**: capas convolucionales de 1, 2 y 3 dimensiones respectivamente. Definidas por el tamaño del kernel que ocupan, el *stride*, filtros de entrada y de salida.\n",
        "* **ReLU**: función de activación. No tiene parámetros.\n",
        "* **Sigmoid**: función de activación. No tiene parámetros.\n",
        "* **Softmax**: capa que transforma el output en una distribución de probabilidad. Parámetro es sobre la o las dimensiones que se aplica.\n",
        "* **MaxPool1d, MaxPool2d, MaxPool3d**: Funciones de pooling en 1,2 y 3 dimensiones respectivamente.\n",
        "* **Dropout**: capa que deja en 0 neuronas con probabilidad $p$. Parámetro: $p$.\n",
        "* **BatchNorm2d**: capa que normaliza el input de acuerdo a una media y varianza aprendidas. \n",
        "* **Sequential**: es un agrupador de Módulos. Se encarga de que la información fluya de forma secuencial entre los módulos que contiene."
      ],
      "metadata": {
        "id": "1JmfrUSLkF2o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "import torch\r\n",
        "from torch.nn import Linear, ReLU, Sigmoid, Sequential, Softmax, BatchNorm1d, BatchNorm2d, Dropout\r\n",
        "\r\n",
        "tensor_prueba = torch.randn((3, 5))\r\n",
        "\r\n",
        "print(tensor_prueba, tensor_prueba.shape)\r\n",
        "\r\n",
        "# Capa Lineal que va de 5 dimensiones a 8\r\n",
        "capa_lineal = Linear(5, 8)\r\n",
        "tensor_nuevo = capa_lineal(tensor_prueba)\r\n",
        "print(\"Tensor después de Capa Lineal:\")\r\n",
        "print(tensor_nuevo, tensor_nuevo.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2807, -1.2771,  0.1691,  0.2889,  0.1852],\n",
            "        [ 0.1168, -0.8020,  0.3120,  1.0509, -0.5027],\n",
            "        [-1.2630, -0.6131,  0.1550, -0.1810,  0.1785]]) torch.Size([3, 5])\n",
            "Tensor después de Capa Lineal:\n",
            "tensor([[ 0.0046, -0.4488,  0.2339, -0.2337,  0.2802, -0.2427, -0.3288, -0.0334],\n",
            "        [-0.1381, -0.4616,  0.1965, -0.6063,  0.4699, -0.3902, -0.4124,  0.5546],\n",
            "        [-0.0630, -0.1041,  0.8334,  0.1500, -0.3313,  0.0122,  0.3275, -0.5771]],\n",
            "       grad_fn=<AddmmBackward>) torch.Size([3, 8])\n"
          ]
        }
      ],
      "metadata": {
        "id": "T6fz8KLbXfXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84237989-2dc8-42e1-c4c3-68bf3baf97e8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# Funciones de Activación\r\n",
        "# ReLU\r\n",
        "relu = ReLU()\r\n",
        "print(\"Antes de ReLU: \")\r\n",
        "print(tensor_prueba)\r\n",
        "print(\"Después de ReLU: \")\r\n",
        "print(relu(tensor_prueba))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antes de ReLU: \n",
            "tensor([[ 0.2807, -1.2771,  0.1691,  0.2889,  0.1852],\n",
            "        [ 0.1168, -0.8020,  0.3120,  1.0509, -0.5027],\n",
            "        [-1.2630, -0.6131,  0.1550, -0.1810,  0.1785]])\n",
            "Después de ReLU: \n",
            "tensor([[0.2807, 0.0000, 0.1691, 0.2889, 0.1852],\n",
            "        [0.1168, 0.0000, 0.3120, 1.0509, 0.0000],\n",
            "        [0.0000, 0.0000, 0.1550, 0.0000, 0.1785]])\n"
          ]
        }
      ],
      "metadata": {
        "id": "ek6q_9qzcFiP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b5a92b3-b3e1-443b-b4d5-8520f33ac586"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Sigmoid\r\n",
        "s = Sigmoid()\r\n",
        "print(\"Antes de Sigmoid: \")\r\n",
        "print(tensor_prueba)\r\n",
        "print(\"Después de Sigmoid: \")\r\n",
        "print(s(tensor_prueba))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antes de Sigmoid: \n",
            "tensor([[ 0.2807, -1.2771,  0.1691,  0.2889,  0.1852],\n",
            "        [ 0.1168, -0.8020,  0.3120,  1.0509, -0.5027],\n",
            "        [-1.2630, -0.6131,  0.1550, -0.1810,  0.1785]])\n",
            "Después de Sigmoid: \n",
            "tensor([[0.5697, 0.2180, 0.5422, 0.5717, 0.5462],\n",
            "        [0.5292, 0.3096, 0.5774, 0.7410, 0.3769],\n",
            "        [0.2205, 0.3513, 0.5387, 0.4549, 0.5445]])\n"
          ]
        }
      ],
      "metadata": {
        "id": "VL3sBxCbcLty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08c5e11-00de-4f8b-bdf1-6b280a87bd9b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Softmax\r\n",
        "soft = Softmax(dim=1)\r\n",
        "print(\"Antes de Softmax: \")\r\n",
        "print(tensor_prueba)\r\n",
        "print(\"Después de Softmax: \")\r\n",
        "soft_tensor = soft(tensor_prueba)\r\n",
        "print(soft_tensor)\r\n",
        "print(soft_tensor.sum(dim=1))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Antes de Softmax: \n",
            "tensor([[ 0.2807, -1.2771,  0.1691,  0.2889,  0.1852],\n",
            "        [ 0.1168, -0.8020,  0.3120,  1.0509, -0.5027],\n",
            "        [-1.2630, -0.6131,  0.1550, -0.1810,  0.1785]])\n",
            "Después de Softmax: \n",
            "tensor([[0.2486, 0.0524, 0.2224, 0.2507, 0.2260],\n",
            "        [0.1755, 0.0700, 0.2133, 0.4467, 0.0945],\n",
            "        [0.0703, 0.1347, 0.2903, 0.2075, 0.2972]])\n",
            "tensor([1.0000, 1.0000, 1.0000])\n"
          ]
        }
      ],
      "metadata": {
        "id": "4pRxMMlacFpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ac8369-2905-4914-a8a6-12ce96af3b1a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# Sequential\r\n",
        "# Unamos pasos\r\n",
        "seq = Sequential(capa_lineal, relu, soft)\r\n",
        "tensor_final = seq(tensor_prueba)\r\n",
        "print(\"Aplicando Sequential: \")\r\n",
        "print(tensor_final, tensor_final.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aplicando Sequential: \n",
            "tensor([[0.1169, 0.1164, 0.1471, 0.1164, 0.1540, 0.1164, 0.1164, 0.1164],\n",
            "        [0.1046, 0.1046, 0.1273, 0.1046, 0.1674, 0.1046, 0.1046, 0.1822],\n",
            "        [0.1014, 0.1014, 0.2333, 0.1178, 0.1014, 0.1026, 0.1407, 0.1014]],\n",
            "       grad_fn=<SoftmaxBackward>) torch.Size([3, 8])\n"
          ]
        }
      ],
      "metadata": {
        "id": "VCDkA0IFcFwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e84c64c-0bca-4e72-f885-500238db8acd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# Dropout\r\n",
        "drop = Dropout(p=0.15) # con probabilidad de dejar en 0 de 0.15.\r\n",
        "tensor_dropout = drop(tensor_prueba)\r\n",
        "print(tensor_dropout)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3302, -1.5024,  0.1989,  0.3399,  0.2179],\n",
            "        [ 0.1374, -0.9435,  0.3671,  1.2364, -0.5914],\n",
            "        [-1.4858, -0.0000,  0.0000, -0.2129,  0.2099]])\n"
          ]
        }
      ],
      "metadata": {
        "id": "kImxDES0Zek6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f04b96-4fe9-4482-81f1-d068c3b076b4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "# Batch Normalization 1d\r\n",
        "tensor_lineal = 100*torch.randn((3, 5))  # Una imagen con varianza alta\r\n",
        "bn = BatchNorm1d(5, momentum=None)                            \r\n",
        "\r\n",
        "\r\n",
        "print(\"La media de los vectores originales por dimensión es: {}\".format(tensor_lineal.mean(dim=[0])))   \r\n",
        "print(\"La varianza de los vectores originales por dimensión es: {}\".format(tensor_lineal.var(dim=[0], unbiased=False)))\r\n",
        "print(\"Las medias por dimensión de BN inicialmente son: {}\".format(bn.running_mean))\r\n",
        "print(\"Las varianzas por dimensión de BN inicialmente son: {}\".format(bn.running_var))\r\n",
        "\r\n",
        "tensor_bn = bn(tensor_lineal)\r\n",
        "\r\n",
        "print(\"La media por dimensión del resultado es: {}\".format(tensor_bn.mean(dim=[0])))   \r\n",
        "print(\"La varianza por dimensión del resultado es: {}\".format(tensor_bn.var(dim=[0], unbiased=False)))\r\n",
        "print(\"Las medias por dimensión de BN ahora son: {}\".format(bn.running_mean))\r\n",
        "print(\"Las varianzas por dimensión de BN ahora son: {}\".format(bn.running_var))  \r\n",
        "\r\n",
        "for n, p in bn.named_parameters():\r\n",
        "    print(n,p)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La media de los vectores originales por dimensión es: tensor([ -8.8861,  82.7486, -18.0518,  68.0079, -20.1341])\n",
            "La varianza de los vectores originales por dimensión es: tensor([   57.9532,  1110.0956,  7958.8735,  7410.4736, 10666.1133])\n",
            "Las medias por dimensión de BN inicialmente son: tensor([0., 0., 0., 0., 0.])\n",
            "Las varianzas por dimensión de BN inicialmente son: tensor([1., 1., 1., 1., 1.])\n",
            "La media por dimensión del resultado es: tensor([-7.9473e-08, -4.2220e-08, -3.9736e-08,  3.9736e-08,  3.9736e-08],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "La varianza por dimensión del resultado es: tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<VarBackward>)\n",
            "Las medias por dimensión de BN ahora son: tensor([ -8.8861,  82.7486, -18.0518,  68.0079, -20.1341])\n",
            "Las varianzas por dimensión de BN ahora son: tensor([   86.9298,  1665.1433, 11938.3105, 11115.7109, 15999.1699])\n",
            "weight Parameter containing:\n",
            "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ],
      "metadata": {
        "id": "TSpvnCsuZwQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a9ddcc-3f6b-4dca-e0f5-b4a6b7b3de56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "# Batch Normalization 2d\r\n",
        "tensor_imagenes = 20*torch.randn((4, 3, 2, 2))  # Una imagen con varianza alta\r\n",
        "bn = BatchNorm2d(3, momentum = None, eps=0.0)                             # 3 es el número de canales\r\n",
        "\r\n",
        "\r\n",
        "print(\"La media de las imágenes originales por canal es: {}\".format(tensor_imagenes.mean(dim=[0,2,3])))   \r\n",
        "print(\"La varianza de las imágenes originales por canal es: {}\".format(tensor_imagenes.var(dim=[0,2,3], unbiased=False)))\r\n",
        "print(\"Las medias por canal de BN inicialmente son: {}\".format(bn.running_mean))\r\n",
        "print(\"Las varianzas por canal de BN inicialmente son: {}\".format(bn.running_var))\r\n",
        "\r\n",
        "tensor_bn = bn(tensor_imagenes)\r\n",
        "\r\n",
        "print(\"La media por canal es: {}\".format(tensor_bn.mean(dim=[0,2,3])))   \r\n",
        "print(\"La varianza por canal es: {}\".format(tensor_bn.var(dim=[0,2,3], unbiased=False)))\r\n",
        "print(\"Las medias por canal de BN ahora son: {}\".format(bn.running_mean))\r\n",
        "print(\"Las varianzas por canal de BN ahora son: {}\".format(bn.running_var))\r\n",
        "\r\n",
        "for n, p in bn.named_parameters():\r\n",
        "    print(n,p)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La media de las imágenes originales por canal es: tensor([-0.5365,  0.7140,  4.6008])\n",
            "La varianza de las imágenes originales por canal es: tensor([581.0929, 488.0320, 458.7324])\n",
            "Las medias por canal de BN inicialmente son: tensor([0., 0., 0.])\n",
            "Las varianzas por canal de BN inicialmente son: tensor([1., 1., 1.])\n",
            "La media por canal es: tensor([ 7.4506e-09,  0.0000e+00, -3.7253e-08], grad_fn=<MeanBackward1>)\n",
            "La varianza por canal es: tensor([1., 1., 1.], grad_fn=<VarBackward>)\n",
            "Las medias por canal de BN ahora son: tensor([-0.5365,  0.7140,  4.6008])\n",
            "Las varianzas por canal de BN ahora son: tensor([619.8325, 520.5674, 489.3145])\n",
            "weight Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True)\n",
            "bias Parameter containing:\n",
            "tensor([0., 0., 0.], requires_grad=True)\n"
          ]
        }
      ],
      "metadata": {
        "id": "rTjNvAWfocwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a9b14c9-6abc-4656-9d7d-915d5ee0eca0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Revisitando AlexNet"
      ],
      "metadata": {
        "id": "vNvplXz5xkUZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "import torch\r\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\r\n",
        "\r\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\r\n",
        "\r\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\r\n",
        "        super(MiAlexNet, self).__init__()\r\n",
        "        # Bloques Convolucionales\r\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\r\n",
        "        # elementos: Convolución, Pooling y Activación.\r\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\r\n",
        "\r\n",
        "\r\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\r\n",
        "        self.conv1 = nn.Sequential(\r\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\r\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\r\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\r\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\r\n",
        "                      stride=(4,4),              # Stride\r\n",
        "                      padding=2),                # Cuántos pixeles de padding\r\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\r\n",
        "            nn.ReLU()                            # Activación                            \r\n",
        "        )\r\n",
        "\r\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\r\n",
        "        self.conv2 = nn.Sequential(\r\n",
        "            nn.Conv2d(                          \r\n",
        "                      in_channels=96,            \r\n",
        "                      out_channels=256,         \r\n",
        "                      kernel_size=(5,5),         \r\n",
        "                      stride=(1,1),              \r\n",
        "                      padding=2),               \r\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\r\n",
        "            nn.ReLU()                                                 \r\n",
        "        )\r\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\r\n",
        "        self.conv3 = nn.Sequential(\r\n",
        "            nn.Conv2d(                           \r\n",
        "                      in_channels=256,          \r\n",
        "                      out_channels=384,         \r\n",
        "                      kernel_size=(3,3),         \r\n",
        "                      stride=(1,1),              \r\n",
        "                      padding=1),                \r\n",
        "            nn.ReLU()                                                     \r\n",
        "        )\r\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\r\n",
        "        self.conv4 = nn.Sequential(\r\n",
        "            nn.Conv2d(                           \r\n",
        "                      in_channels=384,           \r\n",
        "                      out_channels=384,         \r\n",
        "                      kernel_size=(3,3),         \r\n",
        "                      stride=(1,1),              \r\n",
        "                      padding=1),                \r\n",
        "            nn.ReLU()                                            \r\n",
        "        )\r\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\r\n",
        "        self.conv5 = nn.Sequential(\r\n",
        "            nn.Conv2d(                          \r\n",
        "                      in_channels=384,           \r\n",
        "                      out_channels=256,       \r\n",
        "                      kernel_size=(3,3),         \r\n",
        "                      stride=(1,1),          \r\n",
        "                      padding=1),               \r\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\r\n",
        "            nn.ReLU()                                               \r\n",
        "        )\r\n",
        "        ##\r\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\r\n",
        "                                    # resultado convolucional con capas\r\n",
        "                                    # lineales.\r\n",
        "\r\n",
        "        # Bloques Fully Connected/MLP\r\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\r\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\r\n",
        "                                  nn.Linear(9216, 4096), \r\n",
        "                                  nn.ReLU()\r\n",
        "                                  )\r\n",
        "        # Input = 4096 Output = 4096\r\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\r\n",
        "                                  nn.Linear(4096, 4096), \r\n",
        "                                  nn.ReLU()\r\n",
        "                                  )\r\n",
        "        # Input = 4096 Output = 1000\r\n",
        "        self.fc8 = nn.Sequential(\r\n",
        "                                  nn.Linear(4096, 102)\r\n",
        "                                  )\r\n",
        "        \r\n",
        "        self.model = nn.Sequential(self.conv1,self.conv2)\r\n",
        "\r\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\r\n",
        "                                 # Esta red es sencilla pues solo tenemos\r\n",
        "                                 # que conectar las piezas una detrás de la\r\n",
        "                                 # otra. No todas las redes son así.                      \r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.conv2(x)   \r\n",
        "        x = self.conv3(x) \r\n",
        "        x = self.conv4(x)\r\n",
        "        x = self.conv5(x)\r\n",
        "        x = self.flat(x)\r\n",
        "        x = self.fc6(x) \r\n",
        "        x = self.fc7(x)\r\n",
        "        x = self.fc8(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "outputs": [],
      "metadata": {
        "id": "vGXdKoKfxkaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manejo de Datos\n",
        "\n",
        "En un problema normal de Machine Learning, usualmente la gestión de datos no era muy importante dado que los datasets en general son pequeños. Sin embargo, dados los volúmenes de datos que requieren los modelos de aprendizaje profundo, se vuelve difícil mantener los datos en memoria. Por esto, se requiere consumirlos de manera parcelada para poder ocuparlos con las restricciones de hardware que tenemos.\n",
        "\n",
        "Pytorch resuelve el problema mediante dos abstracciones: las clases *Dataset* y *DataLoader*. \n",
        "\n",
        "* La clase *Dataset* trabaja como una interfaz sencilla para acceder nuestros datos físicos.\n",
        "* La clase *DataLoader* se encarga de agrupar los elementos de la clase *Dataset* en *batches* para pasarle a nuestro modelo.\n",
        "\n",
        "Usualmente, el mayor trabajo reside en definir una clase Dataset apropiada para nuestro conjunto de datos. Por suerte, si queremos trabajar con ciertos conjuntos de datos estándar, Pytorch ya tiene definido estos datasets por nosotros.\n",
        "\n",
        "Si no, lo único que tenemos que hacer es definir una clase que herede de torch.utils.data.Dataset y que implemente dos métodos:\n",
        "\n",
        "* \\_\\_len(self)\\_\\_: método que devuelva el tamaño total del dataset.\n",
        "* \\_\\_getitem\\_\\_(self, index): método que entregue un elemento particular del dataset dado un índice (index)."
      ],
      "metadata": {
        "id": "iSvQo9EFkFz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usar Datasets predefinidos"
      ],
      "metadata": {
        "id": "bQI4FW7tm5Kq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "from torchvision.datasets import MNIST, CIFAR10\r\n",
        "\r\n",
        "mnist_train = MNIST(root=\".\", train=True, download=True)\r\n",
        "cifar = CIFAR10(root=\".\", train=True, download=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to .\\cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting .\\cifar-10-python.tar.gz to .\n"
          ]
        }
      ],
      "metadata": {
        "id": "kUu0A4sIm56x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553,
          "referenced_widgets": [
            "8d11c6754705464883e121739c116c79",
            "e020b32c4aa64b0a9fed46039856673d",
            "44ae40351ec54752829429a810b70d8e",
            "cb4dc9dbcc19471c9030d3f865df14c0",
            "435de05354704c7284cfc9e57d0f77c8",
            "fdcdfae618c847a9b5131ff5b9785521",
            "86ded705b75c47adb3df02543a952039",
            "58e6683178784cd8aa305eb3ee3e6c43",
            "c634599d73d24c50b0de07f1d982118f",
            "c17904437ac44dd5af226a183aa23e60",
            "485f22c3d7124962843562151cc55a59",
            "ff1a6140729e415b9f44504f222a25d0",
            "644d02913824465d8bd04c6d12440e90",
            "ffc4902ed3fa487087bd5b004bfb937f",
            "66d5d296d201468e8b48682d47eb3494",
            "88be0abfeaa84cf3aae0d028fe625bd3",
            "4c3a8d3aad164d0d8488fdcd82968d8a",
            "17bab42fe7644caf8c6f6af23280d166",
            "ed5ca0e07e6d452aa616f3b194af3fa6",
            "0435c0d22dc740969f1b6ef7e43bd87b",
            "76cd2b0e08a44349af6c510bb8422496",
            "f7aaa5862db94ec38968cdbc58ab6fb6",
            "0534fd9193cc4ba08ee89d51ed845999",
            "78d6ab99740e454a873effcfdef1f877",
            "a2eded5486aa4ef394db4d81cbef9353",
            "fea4c5f2599946f9a038422b11636bc6",
            "647dfac1a1db4a738a97c12d5002488e",
            "bb5d66ff46ae40068fa51a529d989f21",
            "5518d978182b4cb684566fe8ca66dbee",
            "928631215cb64e3aa0de98ddf3d6b9b5",
            "420678c9ad54422b8885f6c34dfce58e",
            "f5e12767ae684a0d88858112f5617552",
            "92653d40975347f4a768e54fb38c4da1",
            "0c2750b7746746948430392a36df6f20",
            "ee839e95d3c74c899d55b059c381c19c",
            "aba1be7b1abf477889ae418ab67f9447",
            "33e9e5cb4b2d4747ab2b1d0897312fdb",
            "5ec396d11e184bb0aef5961e6134d64a",
            "3438dee479034318b1e2795cb83f0070",
            "881529d3ef374ba9a23294621a8e1c6a",
            "db3dde4a5d654efea44641131455f6a9",
            "a29a59bb80fa44b691def915fe13294a",
            "06f183c27fbc4865baf647bf772ca6b8",
            "8eaca307a6fd45e1afb66236634b8808",
            "c7de1def65a14761912025c2dcc3f75b",
            "18ee03ac1f554233b536eaba2969881f",
            "5286ac7c9fed409685788583b6e4a74d",
            "a5b1d5a1317e4ec082217a5e094554b8",
            "0b77007edf3c485b8d27f7bc13489a56",
            "31c7090efbd0440eb95d918766c3e5d1",
            "07bc5dedb8ee47798033b868ad57a1fb",
            "836807a99f7c4d838837fc3db3937f12",
            "33843c53b36e4bec9d09c6c5cdaae011",
            "4ce4a9b1a4a1435b8c220f6e1cfcccfd",
            "21388bbf1fe645ccba304af08104058f"
          ]
        },
        "outputId": "b0427493-4436-4d2b-d6c3-827128d1fefe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos un ejemplo del dataset."
      ],
      "metadata": {
        "id": "i2Pu0YgnhTNZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "mnist_train[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PIL.Image.Image image mode=L size=28x28 at 0x2693A33C370>, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "metadata": {
        "id": "lcacrRSMhTUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f204c14d-169f-4ba4-e0dc-addcc092ef61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que contiene dos elementos: el primero es una imagen en formato PIL y el segundo es la clase asociada a esa imagen (nuestro target o ground truth). La imagen se ve así:"
      ],
      "metadata": {
        "id": "5U2JVToqhpas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "from IPython.display import display     # Esto no es Pytorch, es solo una librería\r\n",
        "                                        # para desplegar imágenes en Colab.\r\n",
        "display(mnist_train[0][0])\r\n",
        "display(cifar[0][0])"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x269500D6D30>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=32x32 at 0x2690534D460>"
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "id": "CBuDtFpjheKp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "outputId": "0033aa56-ba27-42de-a5a2-8d6ef8376c6e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sin embargo, una imagen en formato PIL no es un tensor de Pytorch. Tenemos que hacer algo para transformarla! Por suerte para nosotros, Pytorch nos ofrece transformaciones estándar para imágenes, en particular, una para transformar imágenes PIL a tensores. Veamos cómo:"
      ],
      "metadata": {
        "id": "uJPBWG9Qh9CD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "from torchvision.transforms import ToTensor\r\n",
        "mnist_train = MNIST(root=\".\", train=True, download=True, transform=ToTensor())"
      ],
      "outputs": [],
      "metadata": {
        "id": "Sw_qKilQiTHk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "mnist_train[9]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7412, 0.7451,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5608, 0.9686, 0.6000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9686, 0.9490, 0.3373,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.7529, 0.9882, 0.7333, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.7255, 0.0706, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.3490, 0.9255, 0.8510, 0.1843, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.8471, 0.9922, 0.2353, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.8314, 1.0000, 0.3176, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.8078, 0.9882, 0.2667, 0.0000,\n",
              "           0.0000, 0.0000, 0.1882, 0.9490, 0.9922, 0.3490, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.5137, 0.9843, 0.8314, 0.0824, 0.0000,\n",
              "           0.0000, 0.0431, 0.6549, 0.9882, 0.7725, 0.0196, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1137, 0.9098, 0.9686, 0.2471, 0.0000, 0.0000,\n",
              "           0.0000, 0.6000, 0.9882, 0.8863, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.1765, 0.8588, 0.9882, 0.5608, 0.0000, 0.0000, 0.0000,\n",
              "           0.4549, 0.9765, 0.9882, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157,\n",
              "           0.3765, 0.9922, 1.0000, 0.9922, 0.7843, 0.4784, 0.0275, 0.0980,\n",
              "           0.7882, 0.9804, 0.6196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3608,\n",
              "           0.9882, 0.9882, 0.9922, 0.8510, 0.9882, 0.9882, 0.7843, 0.8902,\n",
              "           0.9882, 0.9059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412, 0.9843,\n",
              "           0.9686, 0.9059, 0.2549, 0.1882, 0.7412, 0.9882, 0.9882, 0.9922,\n",
              "           0.9882, 0.9843, 0.8902, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7451, 0.8667,\n",
              "           0.3843, 0.0000, 0.0000, 0.0000, 0.1647, 0.7686, 0.9882, 0.9922,\n",
              "           0.9882, 0.9882, 0.6353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4353, 0.1137,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.2431, 0.9373, 0.9882, 0.3373,\n",
              "           0.1647, 0.1647, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0588, 0.5804, 0.9922, 0.8549, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.4745, 0.9882, 0.9059, 0.1098, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.1216, 0.8667, 0.9843, 0.5059, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.8549, 0.9882, 0.6275, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.4784, 0.9882, 0.3216, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 4)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "metadata": {
        "id": "9M-kU58jibL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7453e656-fec8-42ec-f006-4727a7a66fa5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora nuestro Dataset automáticamente transforma las imágenes PIL a tensores de Pytorch!"
      ],
      "metadata": {
        "id": "9TgMYxJCifaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crear un Dataset de ejemplo\n",
        "\n",
        "Vamos a crear un Dataset para el conjunto de datos Flowers que vimos el laboratorio pasado."
      ],
      "metadata": {
        "id": "mRFZkdKJUOjP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "!wget https://www.dropbox.com/s/q53g4cmpnvzhnhi/flowers.tar.gz -q --show-progress\r\n",
        "!tar -xzf flowers.tar.gz"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\"wget\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n",
            "tar: Error opening archive: Failed to open 'flowers.tar.gz'\n"
          ]
        }
      ],
      "metadata": {
        "id": "PlSJdFURr_B8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d55ea3-e79d-4511-b0fc-7753a7821751"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "from os import listdir\r\n",
        "from os.path import join\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\r\n",
        "class Flowers(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, root, transform=None):\r\n",
        "        self.root = root\r\n",
        "        self.transform = transform\r\n",
        "        self.imagenes = []       # Vincula el indice con un nombre de archivo\r\n",
        "        self.imgs_to_class = []  # Vincula el indice con una clase\r\n",
        "        self.imagenes, self.imgs_to_class = self.armar_indices(root)\r\n",
        "    \r\n",
        "    def armar_indices(self, root):\r\n",
        "        n_classes = len(listdir(root)) # El número de carpetas es la cantidad de clases\r\n",
        "        contador = 0\r\n",
        "        lista_imagenes = []\r\n",
        "        imgs_to_class = []\r\n",
        "        for clase in listdir(root):\r\n",
        "            directorio = join(root, clase)\r\n",
        "            for archivo in listdir(directorio):\r\n",
        "                lista_imagenes.append(archivo)\r\n",
        "                contador+=1\r\n",
        "                imgs_to_class.append(int(clase))\r\n",
        "\r\n",
        "        return lista_imagenes, imgs_to_class\r\n",
        "\r\n",
        "    def obtener_imagen(self, archivo):\r\n",
        "        im = Image.open(archivo)\r\n",
        "        return im\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "\r\n",
        "        nombre_archivo = self.imagenes[idx]\r\n",
        "        clase = self.imgs_to_class[idx]\r\n",
        "        ruta_img = join(self.root, str(clase))\r\n",
        "        ruta_img = join(ruta_img, nombre_archivo)\r\n",
        "        img = self.obtener_imagen(ruta_img)\r\n",
        "\r\n",
        "        if self.transform is not None:\r\n",
        "            img = self.transform(img)\r\n",
        "        return img, clase\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        return len(self.imagenes)"
      ],
      "outputs": [],
      "metadata": {
        "id": "6FXcvQ5VUOtH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "transforms = Compose([Resize((224,224)), ToTensor()])\r\n",
        "f = Flowers('flowers_dataset/train', transform=transforms)\r\n",
        "f[0][0].shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "id": "Ahbf-pLNsW-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62c05109-0c41-447f-9d40-2c30b975ae83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterar sobre los datos\n",
        "\n",
        "Dado un Dataset, sea hecho por nosotros o uno predefinido, iterar sobre los datos es muy sencillo. Simplemente tenemos que crear un objeto DataLoader que toma como argumento el Dataset y definir el batch size con que queremos trabajar.\n"
      ],
      "metadata": {
        "id": "5PE9qnWDnzjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código iterará por todos los batches de ejemplos de nuestro dataset y parará cuando se acaben. Es decir, esto corre por una **época**."
      ],
      "metadata": {
        "id": "J9BrWXFcGKKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "from torch.utils.data import DataLoader\r\n",
        "train_dl = DataLoader(f, batch_size=32, shuffle=True)\r\n",
        "\r\n",
        "for n_batch, (x, target) in enumerate(train_dl):\r\n",
        "    print(\"\\rN_Batch: {} input: {}- Label:{}\".format(n_batch, x.shape, target.shape), end=\"\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N_Batch: 177 input: torch.Size([23, 3, 224, 224])- Label:torch.Size([23])"
          ]
        }
      ],
      "metadata": {
        "id": "n5wPTQwiBx2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae323110-204e-45f7-dcac-d9d16b623cbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "\r\n",
        "for img, target in train_dl:\r\n",
        "    print(\"\\rinput: {}- Label:{}\".format(x.shape, target.shape), end=\"\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: torch.Size([23, 3, 224, 224])- Label:torch.Size([23])"
          ]
        }
      ],
      "metadata": {
        "id": "8i2DIQe0f8GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loop de Entrenamiento"
      ],
      "metadata": {
        "id": "OShVxaAFkWY8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimización\n",
        "\n",
        "¿Como obtenemos los pesos óptimos para nuestra red? Si recordamos nuestras clases anteriores debemos optimizar la función de pérdida para tratar de encontrar los parámetros de nuestra red que minimizan su valor.\n",
        "\n",
        "Primero debemos definir la función de pérdida. Éstas están definidas en torch.nn también. Las usuales son:\n",
        "\n",
        "* CrossEntropyLoss: Entropía Cruzada, mide la distancia entre dos distribuciones de probabilidad. La función de pérdida más común para problemas de clasificación.\n",
        "* MSELoss: Error cuadrático medio. Pérdida usual en problemas de regresión.\n",
        "\n",
        "Hay más para revisar en la documentación de Pytorch (https://pytorch.org/docs/stable/nn.html).\n",
        "\n",
        "Dado el resultado de nuestra red y el ground truth que deberíamos predecir, la pérdida es:\n"
      ],
      "metadata": {
        "id": "pco2wPSLBlPB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "source": [
        "from torch.nn import CrossEntropyLoss\r\n",
        "funcion_perdida = CrossEntropyLoss()"
      ],
      "outputs": [],
      "metadata": {
        "id": "hZjFnhvsgb9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss = funcion_perdida(output, target) # No correr este código, va a dar error! Es un ejemplo!"
      ],
      "outputs": [],
      "metadata": {
        "id": "RkR0nWLUDOrD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Súper, tenemos la pérdida, ¿cómo calculamos los gradientes?\n",
        "\n",
        "Para eso necesitamos un algoritmo de optimización. En el curso de Herramientas verán los algoritmos en detalle, pero les debería sonar Stochastic Gradient Descent (SGD), que es el algoritmo estándar de optimización. Este ya está implementado por el paquete torch.optim.\n"
      ],
      "metadata": {
        "id": "z61_pCzKDVPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from torch.optim import SGD\r\n",
        "\r\n",
        "optimizer = SGD(model.parameters())     # Vinculamos el recién creado optimizador\r\n",
        "                                        # a los parámetros de nuestro modelo"
      ],
      "outputs": [],
      "metadata": {
        "id": "zdfXdGgkEFXp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto por sí solo todavía no hace nada. El optimizador va a ir gestionando los gradientes que le llegan a cada parámetro de nuestro modelo. Actualizará los valores de los parámetros de acuerdo al algoritmo de optimización que implemente.\n",
        "\n",
        "Pero para gestionar gradientes tiene que sacarlos de alguna parte. ¡Esto lo hace backpropagation! Por suerte es muy fácil calcularlos en Pytorch."
      ],
      "metadata": {
        "id": "rRakjFJ1Ec8u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "loss.backward()                         # ¡Backpropagation! Eso es todo."
      ],
      "outputs": [],
      "metadata": {
        "id": "U1SEJsy9FocF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego uniendo todas las piezas, en cada iteración de nuestro algoritmo de entrenamiento haremos lo siguiente:"
      ],
      "metadata": {
        "id": "oHc9IlalF1sb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "optimizer.zero_grad()                   # 1. Hacemos cero los gradientes de los parámetros\r\n",
        "output = model(input)                   # 2. Propagamos los datos de entrada por nuestro modelo\r\n",
        "loss = funcion_perdida(output, target)  # 3. Cálculamos la pérdida\r\n",
        "loss.backward()                         # 4. ¡Backpropagation! Calculamos los gradientes \r\n",
        "                                        # para nuestros parámetros. ¡Los gradientes \r\n",
        "                                        # dejan de ser 0!\r\n",
        "optimizer.step()                        # 5. Actualizamos los parámetros de nuestro modelo"
      ],
      "outputs": [],
      "metadata": {
        "id": "O3CqYbbljsJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación de Rendimiento\n",
        "\n",
        "¿Cómo evaluamos el rendimiento? En problemas de clasificación lo que usualmente haremos es comparar el ground truth respecto a lo que predecimos. ¿Qué es lo que predecimos? Usualmente será la clase de mayor valor en su salida entre las N clases que tenemos que predecir. Esto lo podemos hacer usando la función *argmax* de Pytorch."
      ],
      "metadata": {
        "id": "R2lKeEmPkFxN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "output = model(input)                       # Tensor de salida de tamaño (batch_size, n_clases)\r\n",
        "preds = output.argmax(dim=1)                # Nos quedamos con el índice que tiene mayor valor\r\n",
        "                                            # entre las N clases.\r\n",
        "n_correctas = (preds == targets).sum()      # preds == targets entrega un tensor de 1s o 0s.\r\n",
        "total = targets.shape[0]                    # Total de ejemplos\r\n",
        "acc = n_correctas/total                     # Accuracy es correctas/total"
      ],
      "outputs": [],
      "metadata": {
        "id": "wDF-5Ei0_Kkh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uniendo todo\n",
        "\n",
        "Vamos a unir todos estos componentes para armar un flujo de entrenamiento completo:"
      ],
      "metadata": {
        "id": "lNXwwivwjAKo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import torch\r\n",
        "import torch.nn as nn           # Esto es PyTorch y su módulo de Redes Neuronales\r\n",
        "\r\n",
        "class MiAlexNet(nn.Module):               # Esta clase representa nuestro modelo\r\n",
        "\r\n",
        "    def __init__(self):   # Constructor, aquí armamos las piezas de nuestra red\r\n",
        "        super(MiAlexNet, self).__init__()\r\n",
        "        # Bloques Convolucionales\r\n",
        "        # Recordemos que los Bloques Convolucionales van a estar hechos de 3\r\n",
        "        # elementos: Convolución, Pooling y Activación.\r\n",
        "        # En este caso usaremos Convoluciones 2d, Max Pooling y ReLU\r\n",
        "\r\n",
        "\r\n",
        "        # Input = 3x 224 x 224 Output = 96 x 55 x 55 --> Max Pool = 96 x 27 x 27\r\n",
        "        self.conv1 = nn.Sequential(\r\n",
        "            nn.Conv2d(                           # Todo esto define a la Convolución\r\n",
        "                      in_channels=3,             # Filtros/Canales de Entrada (RGB)\r\n",
        "                      out_channels=96,           # Filtros/Canales de Salida\r\n",
        "                      kernel_size=(11,11),       # Tamaño de la Convolución\r\n",
        "                      stride=(4,4),              # Stride\r\n",
        "                      padding=2),                # Cuántos pixeles de padding\r\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)), # Max Pooling\r\n",
        "            nn.ReLU()                            # Activación                            \r\n",
        "        )\r\n",
        "\r\n",
        "        # Input = 96 x 27 x 27 Output = 256 x 27 x 27 --> Max Pool = 256 x 13 x 13\r\n",
        "        self.conv2 = nn.Sequential(\r\n",
        "            nn.Conv2d(                          \r\n",
        "                      in_channels=96,            \r\n",
        "                      out_channels=256,         \r\n",
        "                      kernel_size=(5,5),         \r\n",
        "                      stride=(1,1),              \r\n",
        "                      padding=2),               \r\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\r\n",
        "            nn.ReLU()                                                 \r\n",
        "        )\r\n",
        "        # Input = 256 x 13 x 13 Output = 384 x 13 x 13\r\n",
        "        self.conv3 = nn.Sequential(\r\n",
        "            nn.Conv2d(                           \r\n",
        "                      in_channels=256,          \r\n",
        "                      out_channels=384,         \r\n",
        "                      kernel_size=(3,3),         \r\n",
        "                      stride=(1,1),              \r\n",
        "                      padding=1),                \r\n",
        "            nn.ReLU()                                                     \r\n",
        "        )\r\n",
        "        # Input = 384 x 13 x 13 Output = 384 x 13 x 13\r\n",
        "        self.conv4 = nn.Sequential(\r\n",
        "            nn.Conv2d(                           \r\n",
        "                      in_channels=384,           \r\n",
        "                      out_channels=384,         \r\n",
        "                      kernel_size=(3,3),         \r\n",
        "                      stride=(1,1),              \r\n",
        "                      padding=1),                \r\n",
        "            nn.ReLU()                                            \r\n",
        "        )\r\n",
        "        # Input = 384 x 13 x 13 Output = 256 x 13 x 13 --> MaxPool = 256 x 6 x 6\r\n",
        "        self.conv5 = nn.Sequential(\r\n",
        "            nn.Conv2d(                          \r\n",
        "                      in_channels=384,           \r\n",
        "                      out_channels=256,       \r\n",
        "                      kernel_size=(3,3),         \r\n",
        "                      stride=(1,1),          \r\n",
        "                      padding=1),               \r\n",
        "            nn.MaxPool2d(kernel_size=(3,3), stride=(2,2)),\r\n",
        "            nn.ReLU()                                               \r\n",
        "        )\r\n",
        "        ##\r\n",
        "        self.flat = nn.Flatten()    # Capa aplanamiento para poder vincular\r\n",
        "                                    # resultado convolucional con capas\r\n",
        "                                    # lineales.\r\n",
        "\r\n",
        "        # Bloques Fully Connected/MLP\r\n",
        "        # Input = 256 x 6 x 6 = 9216 Output = 4096\r\n",
        "        self.fc6 = nn.Sequential( #nn.Dropout(),\r\n",
        "                                  nn.Linear(9216, 4096), \r\n",
        "                                  nn.ReLU()\r\n",
        "                                  )\r\n",
        "        # Input = 4096 Output = 4096\r\n",
        "        self.fc7 = nn.Sequential(  #nn.Dropout(),\r\n",
        "                                  nn.Linear(4096, 4096), \r\n",
        "                                  nn.ReLU()\r\n",
        "                                  )\r\n",
        "        # Input = 4096 Output = 1000\r\n",
        "        self.fc8 = nn.Sequential(\r\n",
        "                                  nn.Linear(4096, 102)\r\n",
        "                                  )\r\n",
        "\r\n",
        "    def forward(self, x):        # Aquí armamos cómo se conectan las piezas\r\n",
        "                                 # Esta red es sencilla pues solo tenemos\r\n",
        "                                 # que conectar las piezas una detrás de la\r\n",
        "                                 # otra. No todas las redes son así.                      \r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.conv2(x)   \r\n",
        "        x = self.conv3(x) \r\n",
        "        x = self.conv4(x)\r\n",
        "        x = self.conv5(x)\r\n",
        "        x = self.flat(x)\r\n",
        "        x = self.fc6(x) \r\n",
        "        x = self.fc7(x)\r\n",
        "        x = self.fc8(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "outputs": [],
      "metadata": {
        "id": "AZOhD3d40KXu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "from torch.utils.data import DataLoader\r\n",
        "from torch.optim import Adam\r\n",
        "from torch.nn import CrossEntropyLoss\r\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\r\n",
        "from torchvision.models import alexnet\r\n",
        "\r\n",
        "model = MiAlexNet()\r\n",
        "''' Descomentar esto para ocupar modelo preentrenado\r\n",
        "model = alexnet(pretrained=True)\r\n",
        "model.features.requires_grad_(False)\r\n",
        "model.classifier = nn.Sequential(\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(256 * 6 * 6, 4096),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(4096, 4096),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(4096, 102),\r\n",
        "        )'''\r\n",
        "\r\n",
        "transforms = Compose([Resize((224, 224)), ToTensor()])\r\n",
        "ds_train = Flowers('flowers_dataset/train', transform=transforms)\r\n",
        "\r\n",
        "n_epochs = 10\r\n",
        "train_dl = DataLoader(ds_train, batch_size=128, shuffle=True)\r\n",
        "\r\n",
        "optimizer = Adam(model.parameters(), lr=0.001)    # Creamos nuestro optimizador\r\n",
        "loss_function = CrossEntropyLoss().cuda()      # Creamos la función de pérdida\r\n",
        "\r\n",
        "\r\n",
        "model.train()                           # Dejamos el modelo en modo de entrenamiento\r\n",
        "for epoch in range(1, n_epochs + 1):\r\n",
        "\r\n",
        "    total_correctas = 0.0\r\n",
        "    total_muestras = 0.0\r\n",
        "\r\n",
        "    for x, target in train_dl:          # Iteramos sobre nuestros datos\r\n",
        "        x = x.cuda()\r\n",
        "        target = target.cuda()\r\n",
        "        # Inicio de la iteración\r\n",
        "        optimizer.zero_grad()           # Hacemos cero los gradientes de nuestros parámetros\r\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\r\n",
        "\r\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\r\n",
        "        loss.backward()                          # Backpropagation\r\n",
        "        optimizer.step()                         # Actualizamos parámetros\r\n",
        "\r\n",
        "        # El máximo valor es nuestra predicción\r\n",
        "        preds = output.argmax(dim=1)\r\n",
        "        # Acumulamos las correctas durante la época\r\n",
        "        correctas = (preds == target).sum()\r\n",
        "        total_correctas += correctas\r\n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\r\n",
        "\r\n",
        "        accuracy = total_correctas/total_muestras  # Acc = correctas/total\r\n",
        "\r\n",
        "        print(\r\n",
        "            '\\rEpoca {}: Loss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%'\r\n",
        "            .format(\r\n",
        "                epoch,\r\n",
        "                loss,\r\n",
        "                total_correctas,\r\n",
        "                total_muestras,\r\n",
        "                100*accuracy), end=\"\"\r\n",
        "        )\r\n",
        "    print(\"\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 1: Loss: 4.54 Correctas: 163.0 Total: 5687.0 Accuracy: 2.87%\n",
            "Epoca 2: Loss: 4.17 Correctas: 271.0 Total: 5687.0 Accuracy: 4.77%\n",
            "Epoca 3: Loss: 3.65 Correctas: 385.0 Total: 5687.0 Accuracy: 6.77%\n",
            "Epoca 4: Loss: 3.87 Correctas: 466.0 Total: 5687.0 Accuracy: 8.19%\n",
            "Epoca 5: Loss: 3.34 Correctas: 607.0 Total: 5687.0 Accuracy: 10.67%\n",
            "Epoca 6: Loss: 3.43 Correctas: 736.0 Total: 5687.0 Accuracy: 12.94%\n",
            "Epoca 7: Loss: 3.57 Correctas: 853.0 Total: 5687.0 Accuracy: 15.00%\n",
            "Epoca 8: Loss: 3.48 Correctas: 1028.0 Total: 5687.0 Accuracy: 18.08%\n",
            "Epoca 9: Loss: 2.90 Correctas: 1167.0 Total: 5687.0 Accuracy: 20.52%\n",
            "Epoca 10: Loss: 2.56 Correctas: 1387.0 Total: 5687.0 Accuracy: 24.39%\n"
          ]
        }
      ],
      "metadata": {
        "id": "RCdJwSCajFsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluando el modelo en el conjunto de Test"
      ],
      "metadata": {
        "id": "ZnmpMxT9_ypG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "from torch.utils.data import DataLoader\r\n",
        "from torch.optim import Adam\r\n",
        "from torch.nn import CrossEntropyLoss\r\n",
        "from torchvision.models import alexnet\r\n",
        "ds_test = Flowers(\"flowers_dataset/test\", transform=transforms)\r\n",
        "test_dl = DataLoader(ds_test, batch_size=1024)\r\n",
        "\r\n",
        "total_correctas = 0.0\r\n",
        "total_muestras = 0.0\r\n",
        "\r\n",
        "for x, target in test_dl:          # Iteramos sobre nuestros datos\r\n",
        "    # Inicio de la iteración\r\n",
        "    model.eval()                        # Dejamos el modelo en modo evaluación\r\n",
        "    with torch.no_grad():               # No se calculará información de gradientes\r\n",
        "        # en el código de más abajo.\r\n",
        "        x = x.cuda()\r\n",
        "        target = target.cuda()          # Enviamos nuestros datos a GPU\r\n",
        "        output = model(x)               # Hacemos el forward de nuestros datos\r\n",
        "\r\n",
        "        loss = loss_function(output, target)     # Calculamos la pérdida\r\n",
        "\r\n",
        "        # El máximo valor es nuestra predicción\r\n",
        "        preds = output.argmax(dim=1)\r\n",
        "        # Acumulamos las correctas durante la época\r\n",
        "        correctas = (preds == target).sum()\r\n",
        "        total_correctas += correctas\r\n",
        "        total_muestras += target.shape[0]        # Sumamos el tamaño del batch\r\n",
        "\r\n",
        "        accuracy = total_correctas/total_muestras  # Acc = correctas/total\r\n",
        "\r\n",
        "        print(\r\n",
        "            \"\\rLoss: {:.2f} Correctas: {} Total: {} Accuracy: {:.2f}%\"\r\n",
        "            .format(\r\n",
        "                loss,\r\n",
        "                total_correctas,\r\n",
        "                total_muestras,\r\n",
        "                100*accuracy\r\n",
        "            ),\r\n",
        "            end=\"\"\r\n",
        "        )\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.91 Correctas: 437.0 Total: 1738.0 Accuracy: 25.14%"
          ]
        }
      ],
      "metadata": {
        "id": "oXaeSaTV-KzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afc8c45-9aaf-4d4f-fcfe-fd32dd246de2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guardar el Modelo\n",
        "\n",
        "Una vez entrenado, querremos guardar el modelo para no tener que reentrenarlo cada vez que lo queramos usar. Esto es fácil de hacer en Pytorch. Hay dos formas de hacerlo:\n",
        "\n",
        "* La forma bruta es guardar el objeto completo usando torch.save. Esto guarda todo el objeto a disco. Por lo tanto ocupa más espacio. Pero este no es el mayor problema, sino que el modelo queda vinculado al computador en que se creó. Algo nada apetecible si queremos correr el modelo entrenado en otra máquina. Si se desea proseguir, se hace de la siguiente manera:\n"
      ],
      "metadata": {
        "id": "N0Hrw55cmD-d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "torch.save(model, \"modelo_entrenado.pth\")\r\n",
        "\r\n",
        "modelo = torch.load(\"modelo_entrenado.pth\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "dTj1Wvg_mYlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* La forma más eficiente y correcta es simplemente guardar los pesos. Estos se encuentran en una estructura llamada *'state_dict'* en el modelo. Una vez guardados, para recuperar nuestro modelo, tenemos que crear un modelo nuevo y ocupar el método *'load_state_dict'* para cargar los pesos."
      ],
      "metadata": {
        "id": "NjKpS6ndmd2d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "torch.save(model.state_dict(), \"pesos_modelo_entrenado.pth\") # Guardamos a disco los pesos\r\n",
        "\r\n",
        "modelo = MiAlexNet()                                # Modelo con pesos aleatorios\r\n",
        "pesos = torch.load(\"pesos_modelo_entrenado.pth\") # Cargamos los pesos a una variable\r\n",
        "modelo.load_state_dict(pesos)                       # ¡Los pesos se encuentran \r\n",
        "                                                    # cargados en el modelo!"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {
        "id": "k2NceHcCmd_E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42edf4ac-2fb0-4211-d2a6-d6605e1ddf60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividades\r\n",
        "\r\n",
        "1. Entrene el modelo MiAlexNet por 10 épocas. ¿Qué resultados obtiene en train y test?\r\n",
        "2. Modifique el modelo MiAlexNet para que haya una capa de Dropout antes de FC6 y FC7. Entrénelo por 10 épocas. ¿Ve cambios en el rendimiento del modelo?\r\n",
        "3. Agregue capas de Batch Normalization (*BatchNorm2d*) antes de Conv3, Conv4 y Conv5. Entrene el modelo por 10 épocas. ¿Ve algún cambio en el entrenamiento?\r\n",
        "4. Ocupe el modelo preentrenado en ImageNet de AlexNet. Entrénelo por 10 épocas. ¿Afecta en algo en rendimiento? Para ocupar el modelo preentrenado reemplace esta línea del código de entrenamiento:"
      ],
      "metadata": {
        "id": "_MgIRqm5YaL6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "model = MiAlexNet()     # Creamos el modelo"
      ],
      "outputs": [],
      "metadata": {
        "id": "TPXbZ7F6rpYH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por esta otra línea:"
      ],
      "metadata": {
        "id": "zJPwrpZOrpfL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from torchvision.models import alexnet\r\n",
        "\r\n",
        "model = alexnet(pretrained=True)\r\n",
        "model.features.requires_grad_(False)\r\n",
        "model.classifier = nn.Sequential(\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(256 * 6 * 6, 4096),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Dropout(),\r\n",
        "            nn.Linear(4096, 4096),\r\n",
        "            nn.ReLU(inplace=True),\r\n",
        "            nn.Linear(4096, 102),\r\n",
        "        )"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZjA6rheBq3YC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Respuestas Actividad\n",
        "\n",
        "Por favor, sus respuestas a la actividad acá. No modificar el código anterior."
      ],
      "metadata": {
        "id": "j8Q3BQkaer6E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Actividad 1**"
      ],
      "metadata": {
        "id": "APuyXZZteWZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from torch.utils.data import DataLoader\r\n",
        "from torch.optim import Adam\r\n",
        "from torch.nn import CrossEntropyLoss\r\n",
        "from torchvision.transforms import Compose, ToTensor, Resize\r\n",
        "from torchvision.models import alexnet\r\n",
        "\r\n",
        "model_1 = MiAlexNet().cuda()\r\n",
        "\r\n",
        "def entrenar(modelo, n_epochs=10):\r\n",
        "    train_dl = DataLoader(\r\n",
        "        Flowers(\r\n",
        "            'flowers_dataset/train',\r\n",
        "            transform=Compose([Resize((224, 224)), ToTensor()])\r\n",
        "        ),\r\n",
        "        batch_size=128,\r\n",
        "        shuffle=True,\r\n",
        "        pin_memory=True\r\n",
        "    )\r\n",
        "\r\n",
        "    optimizer = Adam(modelo.parameters(), lr=0.001)\r\n",
        "    loss_function = CrossEntropyLoss().cuda()\r\n",
        "    modelo.train()\r\n",
        "\r\n",
        "    for epoch in range(1, n_epochs + 1):\r\n",
        "        total_correctas = 0.0\r\n",
        "        total_muestras = 0.0\r\n",
        "\r\n",
        "        for x, target in train_dl:\r\n",
        "            x = x.cuda()\r\n",
        "            target = target.cuda()\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "            output = modelo(x)\r\n",
        "\r\n",
        "            loss = loss_function(output, target)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            preds = output.argmax(dim=1)\r\n",
        "\r\n",
        "            correctas = (preds == target).sum()\r\n",
        "            total_correctas += correctas\r\n",
        "            total_muestras += target.shape[0]\r\n",
        "\r\n",
        "            accuracy = 100 * total_correctas / total_muestras\r\n",
        "\r\n",
        "            print(\r\n",
        "                f'\\rEpoca {epoch}: '\r\n",
        "                f'Loss: {loss:.2f} '\r\n",
        "                f'Correctas: {total_correctas} '\r\n",
        "                f'Total: {total_muestras} '\r\n",
        "                f'Accuracy: {accuracy:.2f}%',\r\n",
        "                end=''\r\n",
        "            )\r\n",
        "        print('')\r\n",
        "\r\n",
        "\r\n",
        "entrenar(model_1, n_epochs=10)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 1: Loss: 4.60 Correctas: 146.0 Total: 5687.0 Accuracy: 2.57%\n",
            "Epoca 2: Loss: 3.90 Correctas: 284.0 Total: 5687.0 Accuracy: 4.99%\n",
            "Epoca 3: Loss: 3.88 Correctas: 444.0 Total: 5687.0 Accuracy: 7.81%\n",
            "Epoca 4: Loss: 3.74 Correctas: 551.0 Total: 5687.0 Accuracy: 9.69%\n",
            "Epoca 5: Loss: 3.38 Correctas: 678.0 Total: 5687.0 Accuracy: 11.92%\n",
            "Epoca 6: Loss: 3.62 Correctas: 828.0 Total: 5687.0 Accuracy: 14.56%\n",
            "Epoca 7: Loss: 2.84 Correctas: 966.0 Total: 5687.0 Accuracy: 16.99%\n",
            "Epoca 8: Loss: 2.86 Correctas: 1154.0 Total: 5687.0 Accuracy: 20.29%\n",
            "Epoca 9: Loss: 2.79 Correctas: 1388.0 Total: 5687.0 Accuracy: 24.41%\n",
            "Epoca 10: Loss: 2.52 Correctas: 1549.0 Total: 5687.0 Accuracy: 27.24%\n"
          ]
        }
      ],
      "metadata": {
        "id": "x9OnSDXeeWhF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "def probar(modelo):\r\n",
        "    loss_function = CrossEntropyLoss().cuda()\r\n",
        "    test_dl = DataLoader(\r\n",
        "        Flowers(\r\n",
        "            'flowers_dataset/test',\r\n",
        "            transform=Compose([Resize((224, 224)), ToTensor()])\r\n",
        "        ),\r\n",
        "        batch_size=1024\r\n",
        "    )\r\n",
        "\r\n",
        "    total_correctas = 0.0\r\n",
        "    total_muestras = 0.0\r\n",
        "\r\n",
        "    for x, target in test_dl:\r\n",
        "        modelo.eval()\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "            x = x.cuda()\r\n",
        "            target = target.cuda()\r\n",
        "\r\n",
        "            output = modelo(x)\r\n",
        "            loss = loss_function(output, target)\r\n",
        "            preds = output.argmax(dim=1)\r\n",
        "\r\n",
        "            correctas = (preds == target).sum()\r\n",
        "            total_correctas += correctas\r\n",
        "            total_muestras += target.shape[0]\r\n",
        "\r\n",
        "            accuracy = 100 * total_correctas/total_muestras\r\n",
        "\r\n",
        "            print(\r\n",
        "                f'\\rLoss: {loss:.2f} '\r\n",
        "                f'Correctas: {total_correctas} '\r\n",
        "                f'Total: {total_muestras} '\r\n",
        "                f'Accuracy: {accuracy:.2f}%',\r\n",
        "                end=''\r\n",
        "            )\r\n",
        "\r\n",
        "\r\n",
        "probar(model_1)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.71 Correctas: 457.0 Total: 1738.0 Accuracy: 26.29%"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados son:\r\n",
        "Entrenamiento:  \r\n",
        "Epoca 10: Loss: 2.52 Correctas: 1549.0 Total: 5687.0 Accuracy: 27.24%\r\n",
        "\r\n",
        "Test:\r\n",
        "Loss: 2.71 Correctas: 457.0 Total: 1738.0 Accuracy: 26.29%"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Actividad 2**"
      ],
      "metadata": {
        "id": "fVzxMB2JeWpn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "# 2. Modifique el modelo MiAlexNet para que haya una capa de Dropout antes de FC6 y FC7. Entrénelo por 10 épocas. ¿Ve cambios en el rendimiento del modelo?\r\n",
        "\r\n",
        "class MiAlexNetDropout(MiAlexNet):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.dropout6 = nn.Dropout(p=0.5)\r\n",
        "        self.dropout7 = nn.Dropout(p=0.5)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.conv3(x)\r\n",
        "        x = self.conv4(x)\r\n",
        "        x = self.conv5(x)\r\n",
        "        x = self.flat(x)\r\n",
        "        x = self.dropout6(x)\r\n",
        "        x = self.fc6(x)\r\n",
        "        x = self.dropout7(x)\r\n",
        "        x = self.fc7(x)\r\n",
        "        x = self.fc8(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "modelo_dropout = MiAlexNetDropout().cuda()\r\n",
        "\r\n",
        "entrenar(modelo_dropout, n_epochs=10)\r\n",
        "probar(modelo_dropout)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 1: Loss: 4.50 Correctas: 181.0 Total: 5687.0 Accuracy: 3.18%\n",
            "Epoca 2: Loss: 3.97 Correctas: 331.0 Total: 5687.0 Accuracy: 5.82%\n",
            "Epoca 3: Loss: 3.92 Correctas: 401.0 Total: 5687.0 Accuracy: 7.05%\n",
            "Epoca 4: Loss: 3.81 Correctas: 420.0 Total: 5687.0 Accuracy: 7.39%\n",
            "Epoca 5: Loss: 3.50 Correctas: 498.0 Total: 5687.0 Accuracy: 8.76%\n",
            "Epoca 6: Loss: 3.68 Correctas: 716.0 Total: 5687.0 Accuracy: 12.59%\n",
            "Epoca 7: Loss: 3.21 Correctas: 824.0 Total: 5687.0 Accuracy: 14.49%\n",
            "Epoca 8: Loss: 3.45 Correctas: 993.0 Total: 5687.0 Accuracy: 17.46%\n",
            "Epoca 9: Loss: 2.77 Correctas: 1119.0 Total: 5687.0 Accuracy: 19.68%\n",
            "Epoca 10: Loss: 2.96 Correctas: 1297.0 Total: 5687.0 Accuracy: 22.81%\n",
            "Loss: 2.88 Correctas: 385.0 Total: 1738.0 Accuracy: 22.15%"
          ]
        }
      ],
      "metadata": {
        "id": "srgh6pxteWvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados son:\r\n",
        "\r\n",
        "Entrenamiento:  \r\n",
        "Epoca 10: Loss: 2.96 Correctas: 1297.0 Total: 5687.0 Accuracy: 22.81%\r\n",
        "\r\n",
        "Test:\r\n",
        "Loss: 2.88 Correctas: 385.0 Total: 1738.0 Accuracy: 22.15%\r\n",
        "\r\n",
        "A simple vista no se ve un cambio dramático en el rendimiento, pero si se vuelve más lento obtener los mismos resultados que sin dropout. Tambien me pareció notar que la diferencia del accuracy para el set de training y test es menor, pero creo que sería mas evidente alguna diferencia con muchas mas epocas de entrenamiento.\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Actividad 3**"
      ],
      "metadata": {
        "id": "PDIv-92OeW7W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "# 3. Agregue capas de Batch Normalization (*BatchNorm2d*) antes de Conv3, Conv4 y Conv5. Entrene el modelo por 10 épocas. ¿Ve algún cambio en el entrenamiento?\r\n",
        "class MiAlexNetBatch(MiAlexNet):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "\r\n",
        "        self.batch3 = nn.BatchNorm2d(256)\r\n",
        "        self.batch4 = nn.BatchNorm2d(384)\r\n",
        "        self.batch5 = nn.BatchNorm2d(384)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.batch3(x)\r\n",
        "        x = self.conv3(x)\r\n",
        "        x = self.batch4(x)\r\n",
        "        x = self.conv4(x)\r\n",
        "        x = self.batch5(x)\r\n",
        "        x = self.conv5(x)\r\n",
        "        x = self.flat(x)\r\n",
        "        x = self.fc6(x)\r\n",
        "        x = self.fc7(x)\r\n",
        "        x = self.fc8(x)\r\n",
        "\r\n",
        "        return x\r\n",
        "\r\n",
        "modelo_batch = MiAlexNetBatch().cuda()\r\n",
        "\r\n",
        "entrenar(modelo_batch, n_epochs=10)\r\n",
        "probar(modelo_batch)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 1: Loss: 4.05 Correctas: 285.0 Total: 5687.0 Accuracy: 5.01%\n",
            "Epoca 2: Loss: 3.52 Correctas: 724.0 Total: 5687.0 Accuracy: 12.73%\n",
            "Epoca 3: Loss: 3.37 Correctas: 1046.0 Total: 5687.0 Accuracy: 18.39%\n",
            "Epoca 4: Loss: 2.56 Correctas: 1370.0 Total: 5687.0 Accuracy: 24.09%\n",
            "Epoca 5: Loss: 2.32 Correctas: 1656.0 Total: 5687.0 Accuracy: 29.12%\n",
            "Epoca 6: Loss: 2.36 Correctas: 1910.0 Total: 5687.0 Accuracy: 33.59%\n",
            "Epoca 7: Loss: 2.31 Correctas: 2143.0 Total: 5687.0 Accuracy: 37.68%\n",
            "Epoca 8: Loss: 2.06 Correctas: 2372.0 Total: 5687.0 Accuracy: 41.71%\n",
            "Epoca 9: Loss: 1.62 Correctas: 2535.0 Total: 5687.0 Accuracy: 44.58%\n",
            "Epoca 10: Loss: 1.75 Correctas: 2917.0 Total: 5687.0 Accuracy: 51.29%\n",
            "Loss: 2.74 Correctas: 650.0 Total: 1738.0 Accuracy: 37.40%"
          ]
        }
      ],
      "metadata": {
        "id": "jz27SKTHeXCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados son:\r\n",
        "\r\n",
        "Entrenamiento:  \r\n",
        "Epoca 10: Loss: 1.75 Correctas: 2917.0 Total: 5687.0 Accuracy: 51.29%\r\n",
        "\r\n",
        "Test:\r\n",
        "Loss: 2.74 Correctas: 650.0 Total: 1738.0 Accuracy: 37.40%\r\n",
        "\r\n",
        "añadir capas de Batch Normalization mejoró el accuracy (learning rate) tanto en el set de training como el de test.\r\n",
        "tambien alcanzó mejor rendimiento que la red con dropoup, tal como dice el paper:\r\n",
        "> Remove Dropout. As described in Sec. 3.4, Batch Normalization fulfills some of the same goals as Dropout. Removing Dropout from Modified BN-Inception speeds up\r\n",
        "training, without increasing overfitting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actividad 4"
      ],
      "metadata": {
        "id": "3esj4ZFEeX3w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "# 4. Ocupe el modelo preentrenado en ImageNet de AlexNet. Entrénelo por 10 épocas. ¿Afecta en algo en rendimiento?\r\n",
        "from torchvision.models import alexnet\r\n",
        "\r\n",
        "model_pre = alexnet(pretrained=True)\r\n",
        "model_pre.features.requires_grad_(False)\r\n",
        "model_pre.classifier = nn.Sequential(\r\n",
        "    nn.Dropout(),\r\n",
        "    nn.Linear(256 * 6 * 6, 4096),\r\n",
        "    nn.ReLU(inplace=True),\r\n",
        "    nn.Dropout(),\r\n",
        "    nn.Linear(4096, 4096),\r\n",
        "    nn.ReLU(inplace=True),\r\n",
        "    nn.Linear(4096, 102),\r\n",
        ")\r\n",
        "\r\n",
        "entrenar(model_pre.cuda(), n_epochs=10)\r\n",
        "probar(model_pre)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 1: Loss: 3.01 Correctas: 978.0 Total: 5687.0 Accuracy: 17.20%\n",
            "Epoca 2: Loss: 1.81 Correctas: 2633.0 Total: 5687.0 Accuracy: 46.30%\n",
            "Epoca 3: Loss: 1.26 Correctas: 3355.0 Total: 5687.0 Accuracy: 58.99%\n",
            "Epoca 4: Loss: 1.56 Correctas: 3755.0 Total: 5687.0 Accuracy: 66.03%\n",
            "Epoca 5: Loss: 1.13 Correctas: 4005.0 Total: 5687.0 Accuracy: 70.42%\n",
            "Epoca 6: Loss: 0.94 Correctas: 4154.0 Total: 5687.0 Accuracy: 73.04%\n",
            "Epoca 7: Loss: 1.01 Correctas: 4328.0 Total: 5687.0 Accuracy: 76.10%\n",
            "Epoca 8: Loss: 0.66 Correctas: 4355.0 Total: 5687.0 Accuracy: 76.58%\n",
            "Epoca 9: Loss: 0.95 Correctas: 4491.0 Total: 5687.0 Accuracy: 78.97%\n",
            "Epoca 10: Loss: 0.74 Correctas: 4609.0 Total: 5687.0 Accuracy: 81.04%\n",
            "Loss: 0.75 Correctas: 1344.0 Total: 1738.0 Accuracy: 77.33%"
          ]
        }
      ],
      "metadata": {
        "id": "kMb0lgVdeX9R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados son:\r\n",
        "\r\n",
        "Entrenamiento:  \r\n",
        "Epoca 10: Loss: 0.74 Correctas: 4609.0 Total: 5687.0 Accuracy: 81.04%\r\n",
        "\r\n",
        "Test:\r\n",
        "Loss: 0.75 Correctas: 1344.0 Total: 1738.0 Accuracy: 77.33%\r\n",
        "\r\n",
        "Usar un modelo pre-entrenado mejora considerablemente el rendimiento!\r\n"
      ],
      "metadata": {}
    }
  ]
}